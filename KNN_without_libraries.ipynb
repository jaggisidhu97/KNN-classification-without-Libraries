{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Header files that are needed to import\n",
    "These Header files have builtin tools that could easily help us to wrangle and manage \n",
    "data files\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn import preprocessing  #this header file will help us to convert categorical data to numerical data\n",
    "from sklearn.preprocessing import LabelEncoder #this is the built in function for conversion for categorical to numerical\n",
    "\"\"\"\" Distance measuring functions\"\"\"\n",
    "#1 Euclid Distance Function\n",
    "def edis(q,p): #here the inputs is given to the function and then the distance is calculated\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (q[i] - p[i])**2\n",
    "    return math.sqrt(dist) \n",
    "#2 Manhattan Distance Function\n",
    "def manhat(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += abs(q[i] - p[i])\n",
    "    return (dist) \n",
    "#3 Chi-Square Distance Function\n",
    "def chisquare(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (((p[i] - q[i])**2)/(p[i]+q[i]))\n",
    "    return (dist)\n",
    "cat_names=['Gender','Index']#in my dataset these are the categorical names\n",
    "cont_names=['Height','Weight']#in my dataset these are the continuous names\n",
    "copycont_column_names=['Height_N','Weight_N']#for conversion of categorical to continuous copy of columns are created\n",
    "copycat_column_names=['Gender_N','Index_N']#for conversion of categorical to continuous copy of columns are created\n",
    "numeric_column_names=['Numeric_Gender','Numeric_Index']\n",
    "data_removal=[0.95,0.90,0.80]#this is the list that shows how much of data is needed to remove from the dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 10.44030650891055 after sampling 0.95 % of data\n",
      "Weight : 7.211102550927978 after sampling 0.95 % of data\n",
      "Height : 14.106735979665885 after sampling 0.9 % of data\n",
      "Weight : 12.409673645990857 after sampling 0.9 % of data\n",
      "Height : 18.920887928424502 after sampling 0.8 % of data\n",
      "Weight : 17.233687939614086 after sampling 0.8 % of data\n",
      "Now for 5NN:\n",
      "Height : 168.91098247301744 after sampling 0.95 % of data\n",
      "Weight : 110.74493216395953 after sampling 0.95 % of data\n",
      "Height : 242.56331132304405 after sampling 0.9 % of data\n",
      "Weight : 158.79823676602962 after sampling 0.9 % of data\n",
      "Height : 339.95617364595694 after sampling 0.8 % of data\n",
      "Weight : 221.48878075424045 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction using Euclid Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        df = pd.read_csv('BMI.csv')#CSv file is added\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])#conversion of categorical column to continuous column\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)#division of data according to the loop 5%,10%,20%\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        for j in range(test_features.values.shape[0]):#now we will loop into the features to find distance\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= edis(test_features.values[j],train_features.values[i])#applying euclid distance formula to find distance for \n",
    "                dis_lis[distance]=train_labels.values[i]                        #further prediction\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value \n",
    "#for accuracy measures we have taken the RMS value \n",
    "print(\"Now for 5NN:\")#now whatever we have done we will done for 5NN in to find Euclid Distance\n",
    "\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction using Euclid Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            kn=0\n",
    "            ans=0\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "    \n",
    "            dis_ans.append(ans)  \n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 8.54400374531753 after sampling 0.95 % of data\n",
      "Weight : 6.4031242374328485 after sampling 0.95 % of data\n",
      "Height : 12.96148139681572 after sampling 0.9 % of data\n",
      "Weight : 11.61895003862225 after sampling 0.9 % of data\n",
      "Height : 19.748417658131498 after sampling 0.8 % of data\n",
      "Weight : 19.697715603592208 after sampling 0.8 % of data\n",
      "FOR K=5:\n",
      "Height : 169.68064120576628 after sampling 0.95 % of data\n",
      "Weight : 101.11399507486585 after sampling 0.95 % of data\n",
      "Height : 237.81446549779093 after sampling 0.9 % of data\n",
      "Weight : 160.6572749675532 after sampling 0.9 % of data\n",
      "Height : 339.59316836473613 after sampling 0.8 % of data\n",
      "Weight : 227.39243610991107 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction using Manhat Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)\n",
    "print(\"FOR K=5:\")\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction using Manhat Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            kn=0\n",
    "            ans=0\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "    \n",
    "            dis_ans.append(ans)  \n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 70.26378868236469 after sampling 0.95 % of data\n",
      "Weight : 125.7417989373462 after sampling 0.95 % of data\n",
      "Height : 98.21405194777374 after sampling 0.9 % of data\n",
      "Weight : 148.67750334196495 after sampling 0.9 % of data\n",
      "Height : 143.43291114664027 after sampling 0.8 % of data\n",
      "Weight : 212.3982109152523 after sampling 0.8 % of data\n",
      "FOR K=5:\n",
      "Height : 215.7552316862792 after sampling 0.95 % of data\n",
      "Weight : 93.5348063557091 after sampling 0.95 % of data\n",
      "Height : 284.7368609786938 after sampling 0.9 % of data\n",
      "Weight : 177.92110611166962 after sampling 0.9 % of data\n",
      "Height : 382.7687030048303 after sampling 0.8 % of data\n",
      "Weight : 214.71134110707797 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction using Chi-Square Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        \n",
    "print(\"FOR K=5:\")        \n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction using Chi-Square Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            kn=0\n",
    "            ans=0\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "    \n",
    "            dis_ans.append(ans)  \n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.1622776601683795 after sampling 0.95 % of data\n",
      "Index : 1.4142135623730951 after sampling 0.95 % of data\n",
      "Gender : 5.196152422706632 after sampling 0.9 % of data\n",
      "Index : 2.6457513110645907 after sampling 0.9 % of data\n",
      "Gender : 7.280109889280518 after sampling 0.8 % of data\n",
      "Index : 4.795831523312719 after sampling 0.8 % of data\n",
      "FOR K=5:\n",
      "Gender : 3.3166247903554 after sampling 0.95 % of data\n",
      "Index : 3.3166247903554 after sampling 0.95 % of data\n",
      "Gender : 5.196152422706632 after sampling 0.9 % of data\n",
      "Index : 3.872983346207417 after sampling 0.9 % of data\n",
      "Gender : 6.928203230275509 after sampling 0.8 % of data\n",
      "Index : 4.898979485566356 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction using Euclid Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        \n",
    "print(\"FOR K=5:\")        \n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction using Euclid Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            kn=0\n",
    "            ans=0\n",
    "            voting = {}\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                if dis_lis[key] in voting.keys():\n",
    "                    voting[dis_lis[key]]+=1\n",
    "                else:\n",
    "                    voting[dis_lis[key]]=1\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "            most_vote = 0\n",
    "            most_vote_label = 0\n",
    "            for it in voting.keys():\n",
    "                if most_vote < voting[dis_lis[key]]:\n",
    "                    most_vote=voting[dis_lis[key]]\n",
    "                    most_vote_label = dis_lis[key]\n",
    "            dis_ans.append(most_vote_label)  \n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.4641016151377544 after sampling 0.95 % of data\n",
      "Index : 1.4142135623730951 after sampling 0.95 % of data\n",
      "Gender : 4.58257569495584 after sampling 0.9 % of data\n",
      "Index : 2.23606797749979 after sampling 0.9 % of data\n",
      "Gender : 6.082762530298219 after sampling 0.8 % of data\n",
      "Index : 2.8284271247461903 after sampling 0.8 % of data\n",
      "FOR K=5:\n",
      "Gender : 3.7416573867739413 after sampling 0.95 % of data\n",
      "Index : 2.23606797749979 after sampling 0.95 % of data\n",
      "Gender : 5.291502622129181 after sampling 0.9 % of data\n",
      "Index : 2.8284271247461903 after sampling 0.9 % of data\n",
      "Gender : 6.6332495807108 after sampling 0.8 % of data\n",
      "Index : 5.291502622129181 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction using Manhat Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        \n",
    "print(\"FOR K=5:\")        \n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction using Manhat Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            kn=0\n",
    "            ans=0\n",
    "            voting = {}\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                if dis_lis[key] in voting.keys():\n",
    "                    voting[dis_lis[key]]+=1\n",
    "                else:\n",
    "                    voting[dis_lis[key]]=1\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "            most_vote = 0\n",
    "            most_vote_label = 0\n",
    "            for it in voting.keys():\n",
    "                if most_vote < voting[dis_lis[key]]:\n",
    "                    most_vote=voting[dis_lis[key]]\n",
    "                    most_vote_label = dis_lis[key]\n",
    "            dis_ans.append(most_vote_label)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 4.123105625617661 after sampling 0.95 % of data\n",
      "Index : 3.1622776601683795 after sampling 0.95 % of data\n",
      "Gender : 5.0990195135927845 after sampling 0.9 % of data\n",
      "Index : 9.38083151964686 after sampling 0.9 % of data\n",
      "Gender : 0.0 after sampling 0.8 % of data\n",
      "Index : 5.916079783099616 after sampling 0.8 % of data\n",
      "FOR K=5:\n",
      "Gender : 3.605551275463989 after sampling 0.95 % of data\n",
      "Index : 5.477225575051661 after sampling 0.95 % of data\n",
      "Gender : 4.795831523312719 after sampling 0.9 % of data\n",
      "Index : 5.0990195135927845 after sampling 0.9 % of data\n",
      "Gender : 7.0710678118654755 after sampling 0.8 % of data\n",
      "Index : 5.5677643628300215 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction using Chi-Square Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        \n",
    "print(\"FOR K=5:\")        \n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction using Chi-Square Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            kn=0\n",
    "            ans=0\n",
    "            voting = {}\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                if dis_lis[key] in voting.keys():\n",
    "                    voting[dis_lis[key]]+=1\n",
    "                else:\n",
    "                    voting[dis_lis[key]]=1\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "            most_vote = 0\n",
    "            most_vote_label = 0\n",
    "            for it in voting.keys():\n",
    "                if most_vote < voting[dis_lis[key]]:\n",
    "                    most_vote=voting[dis_lis[key]]\n",
    "                    most_vote_label = dis_lis[key]\n",
    "            dis_ans.append(most_vote_label)  \n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Header files that are needed to import\n",
    "These Header files have builtin tools that could easily help us to wrangle and manage \n",
    "data files\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn import preprocessing #this header file will help us to convert categorical data to numerical data\n",
    "from sklearn.preprocessing import LabelEncoder #this is the built in function for conversion for categorical to numerical\n",
    "\"\"\"\" Distance measuring functions\"\"\"\n",
    "#1 Euclid Distance Function\n",
    "def edis(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (q[i] - p[i])**2\n",
    "    if dist == 0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return (1/((math.sqrt(dist))**2))  \n",
    "#2 Manhattan Distance Function\n",
    "def manhat(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += abs(q[i] - p[i])\n",
    "    if dist == 0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        #return math.sqrt(1/(dist**2))    \n",
    "        return (1/(dist**2)) \n",
    "#3 Chi-Square Distance Function\n",
    "def chisquare(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (((p[i] - q[i])**2)/(0.5+(p[i]+q[i])))\n",
    "    if dist == 0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        #return math.sqrt(1/(dist**2))    \n",
    "        return (1/(dist**2)) \n",
    "cat_names=['Gender','Index']#in my dataset these are the categorical names\n",
    "cont_names=['Height','Weight']#in my dataset these are the continuous names\n",
    "copycont_column_names=['Height_N','Weight_N']#for conversion of categorical to continuous copy of columns are created\n",
    "copycat_column_names=['Gender_N','Index_N']#for conversion of categorical to continuous copy of columns are created\n",
    "numeric_column_names=['Numeric_Gender','Numeric_Index']\n",
    "data_removal=[0.95,0.90,0.80]#this is the list that shows how much of data is needed to remove from the dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 25.748400458149188 after sampling 0.95 % of data\n",
      "Weight : 27.770510185376473 after sampling 0.95 % of data\n",
      "Height : 34.964552098148104 after sampling 0.9 % of data\n",
      "Weight : 25.439409734417662 after sampling 0.9 % of data\n",
      "Height : 48.66183343305843 after sampling 0.8 % of data\n",
      "Weight : 44.596315667353245 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction using Euclid Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "                dis_lis += distance*train_labels.values[i]\n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=dis_lis/dis_sum   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  \n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 22.3087877446863 after sampling 0.95 % of data\n",
      "Weight : 29.05300964655515 after sampling 0.95 % of data\n",
      "Height : 32.9053231549127 after sampling 0.9 % of data\n",
      "Weight : 41.75423265250233 after sampling 0.9 % of data\n",
      "Height : 44.374822636255544 after sampling 0.8 % of data\n",
      "Weight : 54.798797809886324 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction using Manhat Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "                dis_lis += distance*train_labels.values[i]\n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=dis_lis/dis_sum   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  \n",
    "            #print(np.isnan(dis_ans).any())\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 6.69662351963757 after sampling 0.95 % of data\n",
      "Weight : 9.003860568698748 after sampling 0.95 % of data\n",
      "Height : 14.786365586975377 after sampling 0.9 % of data\n",
      "Weight : 9.805546557475374 after sampling 0.9 % of data\n",
      "Height : 29.22559873744649 after sampling 0.8 % of data\n",
      "Weight : 22.77771438809316 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction using chi-square Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]-1):\n",
    "                #print(\"j: \",test_features.values[j])\n",
    "                #print(\"i: \",test_features.values[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "                #print(\"distance: \",distance)\n",
    "                dis_lis += distance*train_labels.values[i]\n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=dis_lis/dis_sum   \n",
    "                       \n",
    "    \n",
    "            dis_ans.append(ans)  \n",
    "            #print(np.isnan(dis_ans).any())\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.3166247903554 after sampling 0.95 % of data\n",
      "Index : 1.4142135623730951 after sampling 0.95 % of data\n",
      "Gender : 4.58257569495584 after sampling 0.9 % of data\n",
      "Index : 2.449489742783178 after sampling 0.9 % of data\n",
      "Gender : 7.0710678118654755 after sampling 0.8 % of data\n",
      "Index : 3.1622776601683795 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction using Euclid Distance Categorical Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            maxx_dis,maxx_lb=0,0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "                dis_lis = distance*train_labels.values[i]\n",
    "                if maxx_dis < distance:\n",
    "                    maxx_dis = distance\n",
    "                    maxx_lb = train_labels.values[i]\n",
    "        \n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=maxx_lb   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans) \n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 2.0 after sampling 0.95 % of data\n",
      "Index : 1.0 after sampling 0.95 % of data\n",
      "Gender : 4.242640687119285 after sampling 0.9 % of data\n",
      "Index : 2.8284271247461903 after sampling 0.9 % of data\n",
      "Gender : 5.385164807134504 after sampling 0.8 % of data\n",
      "Index : 3.1622776601683795 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction using manhat Distance Categorical Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            maxx_dis,maxx_lb=0,0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "                dis_lis = distance*train_labels.values[i]\n",
    "                if maxx_dis < distance:\n",
    "                    maxx_dis = distance\n",
    "                    maxx_lb = train_labels.values[i]\n",
    "        \n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=maxx_lb   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 0.0 after sampling 0.95 % of data\n",
      "Index : 0.0 after sampling 0.95 % of data\n",
      "Gender : 0.0 after sampling 0.9 % of data\n",
      "Index : 1.0 after sampling 0.9 % of data\n",
      "Gender : 0.0 after sampling 0.8 % of data\n",
      "Index : 1.0 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction using chi-square Distance Categorical Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            maxx_dis,maxx_lb=0,0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "                dis_lis = distance*train_labels.values[i]\n",
    "                if maxx_dis < distance:\n",
    "                    maxx_dis = distance\n",
    "                    maxx_lb = train_labels.values[i]\n",
    "        \n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=maxx_lb   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  \n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "#1 Euclid Distance Function\n",
    "def edis(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (q[i] - p[i])**2\n",
    "    return math.sqrt(dist) \n",
    "#2 Manhattan Distance Function\n",
    "def manhat(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += abs(q[i] - p[i])\n",
    "    return (dist) \n",
    "#2 Chi-Square Distance Function\n",
    "def chisquare(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (((p[i] - q[i])**2)/(p[i]+q[i]))\n",
    "    return (dist)\n",
    "cat_names=['Gender','Index']\n",
    "cont_names=['Height','Weight']\n",
    "copycont_column_names=['Height_N','Weight_N']\n",
    "copycat_column_names=['Gender_N','Index_N']\n",
    "numeric_column_names=['Numeric_Gender','Numeric_Index']\n",
    "data_removal=[0.95,0.90,0.80]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 68.67313885355759 after sampling 0.95 % of data\n",
      "Weight : 88.2269800004511 after sampling 0.95 % of data\n",
      "Height : 91.13177272499422 after sampling 0.9 % of data\n",
      "Weight : 119.9291457486461 after sampling 0.9 % of data\n",
      "Height : 133.85813385820077 after sampling 0.8 % of data\n",
      "Weight : 178.83511959344003 after sampling 0.8 % of data\n",
      "Now for 5NN:\n",
      "Height : 196.38665942471755 after sampling 0.95 % of data\n",
      "Weight : 133.60344306940596 after sampling 0.95 % of data\n",
      "Height : 239.59540897104017 after sampling 0.9 % of data\n",
      "Weight : 194.27176840704362 after sampling 0.9 % of data\n",
      "Height : 332.9420369974329 after sampling 0.8 % of data\n",
      "Weight : 287.63838408668624 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Euclid Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value \n",
    "print(\"Now for 5NN:\")\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after Scaling using Euclid Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "        #print(test_labels.values)\n",
    "            kn=0\n",
    "            ans=0\n",
    "        \n",
    "            for key in sorted(dis_lis.keys()):\n",
    "        \n",
    "                ans+=dis_lis[key]\n",
    "            \n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 45.67274898667694 after sampling 0.95 % of data\n",
      "Weight : 53.87021440462252 after sampling 0.95 % of data\n",
      "Height : 97.67292357659824 after sampling 0.9 % of data\n",
      "Weight : 118.93275410920239 after sampling 0.9 % of data\n",
      "Height : 127.4205634895718 after sampling 0.8 % of data\n",
      "Weight : 175.4223474931287 after sampling 0.8 % of data\n",
      "FOR K=5:\n",
      "Height : 161.55642976991044 after sampling 0.95 % of data\n",
      "Weight : 147.0669235416312 after sampling 0.95 % of data\n",
      "Height : 240.95659360142028 after sampling 0.9 % of data\n",
      "Weight : 162.2580660552812 after sampling 0.9 % of data\n",
      "Height : 343.2959656040251 after sampling 0.8 % of data\n",
      "Weight : 280.81346121580424 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Manhat Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(1-i)\n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "       #print(dis_ans)    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)\n",
    "print(\"FOR K=5:\")\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after scaling using Manhat Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(1-i)\n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "        #print(test_labels.values)\n",
    "            kn=0\n",
    "            ans=0\n",
    "        \n",
    "            for key in sorted(dis_lis.keys()):\n",
    "        \n",
    "                ans+=dis_lis[key]\n",
    "            \n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 99.0101004948485 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight : 119.71633138381748 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 119.36079758446657 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight : 177.9297614228716 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 162.3360711610331 after sampling 0.8 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight : 237.9789906693446 after sampling 0.8 % of data\n",
      "FOR K=5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 228.61049844659365 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight : 147.5891594935075 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 265.6704725783428 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight : 223.87961050528924 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 392.1949005277861 after sampling 0.8 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight : 320.20943146634517 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Chi-Square Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(1-i)\n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "       #print(dis_ans)    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)\n",
    "print(\"FOR K=5:\")        \n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after scaling using Chi-Square Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(1-i)\n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "        #print(test_labels.values)\n",
    "            kn=0\n",
    "            ans=0\n",
    "        \n",
    "            for key in sorted(dis_lis.keys()):\n",
    "        \n",
    "                ans+=dis_lis[key]\n",
    "            \n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 0.0 after sampling 0.95 % of data\n",
      "Index : 0.0 after sampling 0.95 % of data\n",
      "Gender : 0.0 after sampling 0.9 % of data\n",
      "Index : 0.0 after sampling 0.9 % of data\n",
      "Gender : 0.0 after sampling 0.8 % of data\n",
      "Index : 0.0 after sampling 0.8 % of data\n",
      "FOR K=5:\n",
      "Gender : 3.4641016151377544 after sampling 0.95 % of data\n",
      "Index : 2.449489742783178 after sampling 0.95 % of data\n",
      "Gender : 5.385164807134504 after sampling 0.9 % of data\n",
      "Index : 3.3166247903554 after sampling 0.9 % of data\n",
      "Gender : 7.615773105863909 after sampling 0.8 % of data\n",
      "Index : 7.54983443527075 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Euclid Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        \n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                #print((train_features.values)[i])\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "                #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "            #print((dis_ans),test_labels.values)    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        \n",
    "print(\"FOR K=5:\")\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after scaling using Euclid Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "    #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "            kn=0\n",
    "            ans=0\n",
    "            voting = {}\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                if dis_lis[key] in voting.keys():\n",
    "                    voting[dis_lis[key]]+=1\n",
    "                else:\n",
    "                    voting[dis_lis[key]]=1\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "            most_vote = 0\n",
    "            most_vote_label = 0\n",
    "            for it in voting.keys():\n",
    "                if most_vote < voting[dis_lis[key]]:\n",
    "                    most_vote=voting[dis_lis[key]]\n",
    "                    most_vote_label = dis_lis[key]\n",
    "            #print(voting)\n",
    "            #print(most_vote_label)\n",
    "            dis_ans.append(most_vote_label)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 0.0 after sampling 0.95 % of data\n",
      "Index : 0.0 after sampling 0.95 % of data\n",
      "Gender : 0.0 after sampling 0.9 % of data\n",
      "Index : 0.0 after sampling 0.9 % of data\n",
      "Gender : 0.0 after sampling 0.8 % of data\n",
      "Index : 0.0 after sampling 0.8 % of data\n",
      "FOR K=5:\n",
      "Gender : 4.0 after sampling 0.95 % of data\n",
      "Index : 1.7320508075688772 after sampling 0.95 % of data\n",
      "Gender : 4.58257569495584 after sampling 0.9 % of data\n",
      "Index : 3.3166247903554 after sampling 0.9 % of data\n",
      "Gender : 7.615773105863909 after sampling 0.8 % of data\n",
      "Index : 4.69041575982343 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "# 1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Manhat Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        \n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "                #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "            #print((dis_ans),test_labels.values)    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        \n",
    "print(\"FOR K=5:\")\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after scaling using Manhat Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "    #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "            kn=0\n",
    "            ans=0\n",
    "            voting = {}\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                if dis_lis[key] in voting.keys():\n",
    "                    voting[dis_lis[key]]+=1\n",
    "                else:\n",
    "                    voting[dis_lis[key]]=1\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "            most_vote = 0\n",
    "            most_vote_label = 0\n",
    "            for it in voting.keys():\n",
    "                if most_vote < voting[dis_lis[key]]:\n",
    "                    most_vote=voting[dis_lis[key]]\n",
    "                    most_vote_label = dis_lis[key]\n",
    "            #print(voting)\n",
    "            #print(most_vote_label)\n",
    "            dis_ans.append(most_vote_label)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.7416573867739413 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 6.6332495807108 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 5.291502622129181 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 4.898979485566356 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 7.211102550927978 after sampling 0.8 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 8.246211251235321 after sampling 0.8 % of data\n",
      "FOR K=5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.1622776601683795 after sampling 0.95 % of data\n",
      "Index : 3.0 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 4.69041575982343 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 5.477225575051661 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 7.0710678118654755 after sampling 0.8 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 7.54983443527075 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Chi-Square Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        \n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "                #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "            #print((dis_ans),test_labels.values)    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        \n",
    "print(\"FOR K=5:\")\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after scaling using Chi-Square Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "    #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "            kn=0\n",
    "            ans=0\n",
    "            voting = {}\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                if dis_lis[key] in voting.keys():\n",
    "                    voting[dis_lis[key]]+=1\n",
    "                else:\n",
    "                    voting[dis_lis[key]]=1\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "            most_vote = 0\n",
    "            most_vote_label = 0\n",
    "            for it in voting.keys():\n",
    "                if most_vote < voting[dis_lis[key]]:\n",
    "                    most_vote=voting[dis_lis[key]]\n",
    "                    most_vote_label = dis_lis[key]\n",
    "            #print(voting)\n",
    "            #print(most_vote_label)\n",
    "            dis_ans.append(most_vote_label)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Header files that are needed to import\n",
    "These Header files have builtin tools that could easily help us to wrangle and manage \n",
    "data files\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "def edis(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (q[i] - p[i])**2\n",
    "    if dist == 0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return (1/((math.sqrt(dist))**2))  \n",
    "def manhat(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += abs(q[i] - p[i])\n",
    "    if dist == 0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        #return math.sqrt(1/(dist**2))    \n",
    "        return (1/(dist**2)) \n",
    "def chisquare(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (((p[i] - q[i])**2)/(0.5+(p[i]+q[i])))\n",
    "    if dist == 0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        #return math.sqrt(1/(dist**2))    \n",
    "        return (1/(dist**2)) \n",
    "cat_names=['Gender','Index']\n",
    "cont_names=['Height','Weight']\n",
    "copycont_column_names=['Height_N','Weight_N']\n",
    "copycat_column_names=['Gender_N','Index_N']\n",
    "numeric_column_names=['Numeric_Gender','Numeric_Index']\n",
    "data_removal=[0.95,0.90,0.80]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 42.39420976429624 after sampling 0.95 % of data\n",
      "Weight : 74.39418708611761 after sampling 0.95 % of data\n",
      "Height : 75.28168016608855 after sampling 0.9 % of data\n",
      "Weight : 114.04026980379804 after sampling 0.9 % of data\n",
      "Height : 102.78828926413146 after sampling 0.8 % of data\n",
      "Weight : 140.15112712893892 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction after scaling using Euclid Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        #print(1-i)\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis += distance*train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=dis_lis/dis_sum   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 57.8328418197285 after sampling 0.95 % of data\n",
      "Weight : 69.66558499847542 after sampling 0.95 % of data\n",
      "Height : 82.54886897915159 after sampling 0.9 % of data\n",
      "Weight : 99.0977939777608 after sampling 0.9 % of data\n",
      "Height : 98.14795025353656 after sampling 0.8 % of data\n",
      "Weight : 142.49485807567183 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction after scaling using Manhat Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        #print(1-i)\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis += distance*train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=dis_lis/dis_sum   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 71.72610338907062 after sampling 0.95 % of data\n",
      "Weight : 71.90901733102164 after sampling 0.95 % of data\n",
      "Height : 72.72370987049665 after sampling 0.9 % of data\n",
      "Weight : 92.92111326802376 after sampling 0.9 % of data\n",
      "Height : 102.25462737366676 after sampling 0.8 % of data\n",
      "Weight : 156.60418939298538 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction after scaling using chi-square Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        #print(1-i)\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis += distance*train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=dis_lis/dis_sum   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.872983346207417 after sampling 0.95 % of data\n",
      "Index : 1.4142135623730951 after sampling 0.95 % of data\n",
      "Gender : 5.5677643628300215 after sampling 0.9 % of data\n",
      "Index : 2.6457513110645907 after sampling 0.9 % of data\n",
      "Gender : 7.0 after sampling 0.8 % of data\n",
      "Index : 4.58257569495584 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction after scaling using Euclid Distance Categorical Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "            \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            maxx_dis,maxx_lb=0,0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis = distance*train_labels.values[i]\n",
    "                if maxx_dis < distance:\n",
    "                    maxx_dis = distance\n",
    "                    maxx_lb = train_labels.values[i]\n",
    "        \n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    #if cat retrun max_lb\n",
    "    \n",
    "        \n",
    "            ans=maxx_lb   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.4641016151377544 after sampling 0.95 % of data\n",
      "Index : 1.0 after sampling 0.95 % of data\n",
      "Gender : 4.47213595499958 after sampling 0.9 % of data\n",
      "Index : 3.1622776601683795 after sampling 0.9 % of data\n",
      "Gender : 7.211102550927978 after sampling 0.8 % of data\n",
      "Index : 4.69041575982343 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction after scaling using manhat Distance Categorical Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "            \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            maxx_dis,maxx_lb=0,0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis = distance*train_labels.values[i]\n",
    "                if maxx_dis < distance:\n",
    "                    maxx_dis = distance\n",
    "                    maxx_lb = train_labels.values[i]\n",
    "        \n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    #if cat retrun max_lb\n",
    "    \n",
    "        \n",
    "            ans=maxx_lb   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.605551275463989 after sampling 0.95 % of data\n",
      "Index : 1.0 after sampling 0.95 % of data\n",
      "Gender : 4.898979485566356 after sampling 0.9 % of data\n",
      "Index : 4.0 after sampling 0.9 % of data\n",
      "Gender : 7.0710678118654755 after sampling 0.8 % of data\n",
      "Index : 4.898979485566356 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#### weighted with 5%,10%,20% removal of Data and getting prediction after scaling using chi-square Distance Categorical Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "            \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            maxx_dis,maxx_lb=0,0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis = distance*train_labels.values[i]\n",
    "                if maxx_dis < distance:\n",
    "                    maxx_dis = distance\n",
    "                    maxx_lb = train_labels.values[i]\n",
    "        \n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    #if cat retrun max_lb\n",
    "    \n",
    "        \n",
    "            ans=maxx_lb   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#1 Euclid Distance Function\n",
    "def edis(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (q[i] - p[i])**2\n",
    "    return math.sqrt(dist) \n",
    "#2 Manhattan Distance Function\n",
    "def manhat(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += abs(q[i] - p[i])\n",
    "    return (dist) \n",
    "#2 Chi-Square Distance Function\n",
    "def chisquare(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (((p[i] - q[i])**2)/(p[i]+q[i]))\n",
    "    return (dist)\n",
    "cat_names=['Gender','Index']\n",
    "cont_names=['Height','Weight']\n",
    "copycont_column_names=['Height_N','Weight_N']\n",
    "copycat_column_names=['Gender_N','Index_N']\n",
    "numeric_column_names=['Numeric_Gender','Numeric_Index']\n",
    "data_removal=[0.95,0.90,0.80]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 58.957611891934704 after sampling 0.95 % of data\n",
      "Weight : 63.079315151640635 after sampling 0.95 % of data\n",
      "Height : 100.39920318408906 after sampling 0.9 % of data\n",
      "Weight : 107.0 after sampling 0.9 % of data\n",
      "Height : 131.18307817702708 after sampling 0.8 % of data\n",
      "Weight : 210.19514742257968 after sampling 0.8 % of data\n",
      "Now for 5NN:\n",
      "Height : 193.53883331259388 after sampling 0.95 % of data\n",
      "Weight : 118.38006588949004 after sampling 0.95 % of data\n",
      "Height : 248.3766494660881 after sampling 0.9 % of data\n",
      "Weight : 202.39199588916554 after sampling 0.9 % of data\n",
      "Height : 347.2725730604132 after sampling 0.8 % of data\n",
      "Weight : 278.0253225877096 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Euclid Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(1-i)\n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "       #print(dis_ans)    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value \n",
    "print(\"Now for 5NN:\")\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after Scaling using Euclid Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(1-i)\n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "        #print(test_labels.values)\n",
    "            kn=0\n",
    "            ans=0\n",
    "        \n",
    "            for key in sorted(dis_lis.keys()):\n",
    "        \n",
    "                ans+=dis_lis[key]\n",
    "            \n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 87.48714191239762 after sampling 0.95 % of data\n",
      "Weight : 133.13526955694348 after sampling 0.95 % of data\n",
      "Height : 87.34414691323055 after sampling 0.9 % of data\n",
      "Weight : 125.1119498689074 after sampling 0.9 % of data\n",
      "Height : 148.62368586466962 after sampling 0.8 % of data\n",
      "Weight : 164.7604321431575 after sampling 0.8 % of data\n",
      "FOR K=5:\n",
      "Height : 176.48535349994347 after sampling 0.95 % of data\n",
      "Weight : 117.33524619652869 after sampling 0.95 % of data\n",
      "Height : 227.4116092023448 after sampling 0.9 % of data\n",
      "Weight : 192.68066846469054 after sampling 0.9 % of data\n",
      "Height : 330.8170491374348 after sampling 0.8 % of data\n",
      "Weight : 278.0192799069877 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Manhat Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(1-i)\n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "       #print(dis_ans)    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)\n",
    "print(\"FOR K=5:\")\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after scaling using Manhat Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(1-i)\n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "        #print(test_labels.values)\n",
    "            kn=0\n",
    "            ans=0\n",
    "        \n",
    "            for key in sorted(dis_lis.keys()):\n",
    "        \n",
    "                ans+=dis_lis[key]\n",
    "            \n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 145.8320952328396 after sampling 0.95 % of data\n",
      "Weight : 294.66930617219026 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 141.17719362559944 after sampling 0.9 % of data\n",
      "Weight : 384.7973492632193 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 208.00961516237658 after sampling 0.8 % of data\n",
      "Weight : 554.813482172162 after sampling 0.8 % of data\n",
      "FOR K=5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 193.7551031586007 after sampling 0.95 % of data\n",
      "Weight : 282.0151059783855 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 292.40882339628536 after sampling 0.9 % of data\n",
      "Weight : 348.606941984809 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 405.3211072717531 after sampling 0.8 % of data\n",
      "Weight : 484.62744453858573 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Chi-Square Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(1-i)\n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "       #print(dis_ans)    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)\n",
    "print(\"FOR K=5:\")        \n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after scaling using Chi-Square Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(1-i)\n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        \n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "        #print(test_labels.values)\n",
    "            kn=0\n",
    "            ans=0\n",
    "        \n",
    "            for key in sorted(dis_lis.keys()):\n",
    "        \n",
    "                ans+=dis_lis[key]\n",
    "            \n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 0.0 after sampling 0.95 % of data\n",
      "Index : 0.0 after sampling 0.95 % of data\n",
      "Gender : 0.0 after sampling 0.9 % of data\n",
      "Index : 0.0 after sampling 0.9 % of data\n",
      "Gender : 0.0 after sampling 0.8 % of data\n",
      "Index : 1.0 after sampling 0.8 % of data\n",
      "FOR K=5:\n",
      "Gender : 3.3166247903554 after sampling 0.95 % of data\n",
      "Index : 2.449489742783178 after sampling 0.95 % of data\n",
      "Gender : 5.656854249492381 after sampling 0.9 % of data\n",
      "Index : 4.123105625617661 after sampling 0.9 % of data\n",
      "Gender : 7.0 after sampling 0.8 % of data\n",
      "Index : 7.0 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Euclid Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        \n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                #print((train_features.values)[i])\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "                #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "            #print((dis_ans),test_labels.values)    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        \n",
    "print(\"FOR K=5:\")\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after scaling using Euclid Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "    #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "            kn=0\n",
    "            ans=0\n",
    "            voting = {}\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                if dis_lis[key] in voting.keys():\n",
    "                    voting[dis_lis[key]]+=1\n",
    "                else:\n",
    "                    voting[dis_lis[key]]=1\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "            most_vote = 0\n",
    "            most_vote_label = 0\n",
    "            for it in voting.keys():\n",
    "                if most_vote < voting[dis_lis[key]]:\n",
    "                    most_vote=voting[dis_lis[key]]\n",
    "                    most_vote_label = dis_lis[key]\n",
    "            #print(voting)\n",
    "            #print(most_vote_label)\n",
    "            dis_ans.append(most_vote_label)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 0.0 after sampling 0.95 % of data\n",
      "Index : 0.0 after sampling 0.95 % of data\n",
      "Gender : 0.0 after sampling 0.9 % of data\n",
      "Index : 0.0 after sampling 0.9 % of data\n",
      "Gender : 0.0 after sampling 0.8 % of data\n",
      "Index : 0.0 after sampling 0.8 % of data\n",
      "FOR K=5:\n",
      "Gender : 3.3166247903554 after sampling 0.95 % of data\n",
      "Index : 3.872983346207417 after sampling 0.95 % of data\n",
      "Gender : 4.795831523312719 after sampling 0.9 % of data\n",
      "Index : 4.898979485566356 after sampling 0.9 % of data\n",
      "Gender : 6.855654600401044 after sampling 0.8 % of data\n",
      "Index : 6.244997998398398 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Manhat Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        \n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "                #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "            #print((dis_ans),test_labels.values)    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        \n",
    "print(\"FOR K=5:\")\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after scaling using Manhat Distance Categorical Column        \n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "    #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "            kn=0\n",
    "            ans=0\n",
    "            voting = {}\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                if dis_lis[key] in voting.keys():\n",
    "                    voting[dis_lis[key]]+=1\n",
    "                else:\n",
    "                    voting[dis_lis[key]]=1\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "            most_vote = 0\n",
    "            most_vote_label = 0\n",
    "            for it in voting.keys():\n",
    "                if most_vote < voting[dis_lis[key]]:\n",
    "                    most_vote=voting[dis_lis[key]]\n",
    "                    most_vote_label = dis_lis[key]\n",
    "            #print(voting)\n",
    "            #print(most_vote_label)\n",
    "            dis_ans.append(most_vote_label)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 4.358898943540674 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 13.19090595827292 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 5.5677643628300215 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 17.72004514666935 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 7.874007874011811 after sampling 0.8 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 22.80350850198276 after sampling 0.8 % of data\n",
      "FOR K=5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.4641016151377544 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 11.61895003862225 after sampling 0.95 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 5.0990195135927845 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 16.97056274847714 after sampling 0.9 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 7.0710678118654755 after sampling 0.8 % of data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "C:\\Users\\Jagmeet Singh Sidhu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : 25.41653005427767 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#1NN with 5%,10%,20% removal of Data and getting prediction after scaling using Chi-Square Distance Categorical Column\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        \n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "                #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "                #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                dis_ans.append(dis_lis[key])\n",
    "                break\n",
    "            #print((dis_ans),test_labels.values)    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        \n",
    "print(\"FOR K=5:\")\n",
    "#5NN with 5%,10%,20% removal of Data and getting prediction after scaling using Chi-Square Distance Categorical Column        \n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "    #print((test_features.values)[j])\n",
    "            dis_lis={}\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis[distance]=train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "            kn=0\n",
    "            ans=0\n",
    "            voting = {}\n",
    "            for key in sorted(dis_lis.keys()):\n",
    "                if dis_lis[key] in voting.keys():\n",
    "                    voting[dis_lis[key]]+=1\n",
    "                else:\n",
    "                    voting[dis_lis[key]]=1\n",
    "                ans+= dis_lis[key]\n",
    "                if kn >= K:\n",
    "                    ans=ans/K\n",
    "                    break\n",
    "                kn+=1\n",
    "            most_vote = 0\n",
    "            most_vote_label = 0\n",
    "            for it in voting.keys():\n",
    "                if most_vote < voting[dis_lis[key]]:\n",
    "                    most_vote=voting[dis_lis[key]]\n",
    "                    most_vote_label = dis_lis[key]\n",
    "            #print(voting)\n",
    "            #print(most_vote_label)\n",
    "            dis_ans.append(most_vote_label)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "def edis(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (q[i] - p[i])**2\n",
    "    if dist == 0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return (1/((math.sqrt(dist))**2))  \n",
    "def manhat(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += abs(q[i] - p[i])\n",
    "    if dist == 0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        #return math.sqrt(1/(dist**2))    \n",
    "        return (1/(dist**2)) \n",
    "def chisquare(q,p):\n",
    "    dist=0\n",
    "    for i in range(len(q)):\n",
    "        dist += (((p[i] - q[i])**2)/(0.5+(p[i]+q[i])))\n",
    "    if dist == 0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        #return math.sqrt(1/(dist**2))    \n",
    "        return (1/(dist**2)) \n",
    "cat_names=['Gender','Index']\n",
    "cont_names=['Height','Weight']\n",
    "copycont_column_names=['Height_N','Weight_N']\n",
    "copycat_column_names=['Gender_N','Index_N']\n",
    "numeric_column_names=['Numeric_Gender','Numeric_Index']\n",
    "data_removal=[0.95,0.90,0.80]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 58.58912183928254 after sampling 0.95 % of data\n",
      "Weight : 85.58117058422569 after sampling 0.95 % of data\n",
      "Height : 74.80208902428897 after sampling 0.9 % of data\n",
      "Weight : 97.25029600925794 after sampling 0.9 % of data\n",
      "Height : 107.70670386046069 after sampling 0.8 % of data\n",
      "Weight : 146.83535206755064 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction after scaling using Euclid Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        #print(1-i)\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis += distance*train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=dis_lis/dis_sum   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 47.48907671789475 after sampling 0.95 % of data\n",
      "Weight : 77.1816390069335 after sampling 0.95 % of data\n",
      "Height : 73.59372907994653 after sampling 0.9 % of data\n",
      "Weight : 96.29365459171164 after sampling 0.9 % of data\n",
      "Height : 103.93299121607252 after sampling 0.8 % of data\n",
      "Weight : 148.84990631937774 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction after scaling using Manhat Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        #print(1-i)\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis += distance*train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=dis_lis/dis_sum   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height : 71.33243745579624 after sampling 0.95 % of data\n",
      "Weight : 97.97250260073861 after sampling 0.95 % of data\n",
      "Height : 61.397845443562964 after sampling 0.9 % of data\n",
      "Weight : 151.36791167372914 after sampling 0.9 % of data\n",
      "Height : 98.0003219433085 after sampling 0.8 % of data\n",
      "Weight : 199.966673381421 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction after scaling using chi-square Distance Continuous Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cont_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "        df = df.drop(['Gender'],axis=1)\n",
    "        df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "        df = df.drop(['Index'],axis=1)\n",
    "        df[copycont_column_names[colname]]=df[cont_names[colname]]\n",
    "        #print(1-i)\n",
    "        df[cont_names[colname]]=df[cont_names[colname]].sample(frac = fr)\n",
    "        \n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cont_names[colname])\n",
    "        ls.remove(copycont_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        \n",
    "        #print(df)\n",
    "        test_data = df[pd.isnull(df[cont_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cont_names[colname]])==False]\n",
    "        train_features = train_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cont_names[colname]]       \n",
    "        test_features = test_data.drop([cont_names[colname],copycont_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycont_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis += distance*train_labels.values[i]\n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    \n",
    "        \n",
    "            ans=dis_lis/dis_sum   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cont_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.7416573867739413 after sampling 0.95 % of data\n",
      "Index : 2.0 after sampling 0.95 % of data\n",
      "Gender : 5.0990195135927845 after sampling 0.9 % of data\n",
      "Index : 3.1622776601683795 after sampling 0.9 % of data\n",
      "Gender : 6.928203230275509 after sampling 0.8 % of data\n",
      "Index : 3.7416573867739413 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction after scaling using Euclid Distance Categorical Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "            \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            maxx_dis,maxx_lb=0,0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= edis(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis = distance*train_labels.values[i]\n",
    "                if maxx_dis < distance:\n",
    "                    maxx_dis = distance\n",
    "                    maxx_lb = train_labels.values[i]\n",
    "        \n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    #if cat retrun max_lb\n",
    "    \n",
    "        \n",
    "            ans=maxx_lb   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.3166247903554 after sampling 0.95 % of data\n",
      "Index : 2.449489742783178 after sampling 0.95 % of data\n",
      "Gender : 4.898979485566356 after sampling 0.9 % of data\n",
      "Index : 3.872983346207417 after sampling 0.9 % of data\n",
      "Gender : 7.14142842854285 after sampling 0.8 % of data\n",
      "Index : 4.358898943540674 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#weighted with 5%,10%,20% removal of Data and getting prediction after scaling using manhat Distance Categorical Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "            \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            maxx_dis,maxx_lb=0,0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= manhat(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis = distance*train_labels.values[i]\n",
    "                if maxx_dis < distance:\n",
    "                    maxx_dis = distance\n",
    "                    maxx_lb = train_labels.values[i]\n",
    "        \n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    #if cat retrun max_lb\n",
    "    \n",
    "        \n",
    "            ans=maxx_lb   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : 3.4641016151377544 after sampling 0.95 % of data\n",
      "Index : 2.449489742783178 after sampling 0.95 % of data\n",
      "Gender : 5.0 after sampling 0.9 % of data\n",
      "Index : 5.477225575051661 after sampling 0.9 % of data\n",
      "Gender : 6.782329983125268 after sampling 0.8 % of data\n",
      "Index : 6.557438524302 after sampling 0.8 % of data\n"
     ]
    }
   ],
   "source": [
    "#### weighted with 5%,10%,20% removal of Data and getting prediction after scaling using chi-square Distance Categorical Columns\n",
    "for i in range(3):\n",
    "    fr=data_removal[i]\n",
    "    for colname in range(len(cat_names)):\n",
    "        #print(df[cont_names[colname]])\n",
    "        df = pd.read_csv('BMI.csv')\n",
    "        if cat_names[colname]=='Gender':\n",
    "            df['Numeric_Index']= LabelEncoder().fit_transform(df['Index'])\n",
    "            df = df.drop(['Index'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "        else:\n",
    "            df['Numeric_Gender']= LabelEncoder().fit_transform(df['Gender'])\n",
    "            df = df.drop(['Gender'],axis=1)\n",
    "            df[cat_names[colname]]= LabelEncoder().fit_transform(df[cat_names[colname]])\n",
    "            df[copycat_column_names[colname]]=df[cat_names[colname]]\n",
    "            \n",
    "        df[cat_names[colname]]=df[cat_names[colname]].sample(frac = fr)\n",
    "        ls = list(df.columns)\n",
    "        ls.remove(cat_names[colname])\n",
    "        ls.remove(copycat_column_names[colname])\n",
    "        df[ls] = scaler.fit_transform(df[ls])\n",
    "        test_data = df[pd.isnull(df[cat_names[colname]])]#divinding testing and training data\n",
    "        train_data = df[pd.isnull(df[cat_names[colname]])==False]\n",
    "        train_features = train_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        train_labels = train_data[cat_names[colname]]       \n",
    "        test_features = test_data.drop([cat_names[colname],copycat_column_names[colname]],axis=1)\n",
    "        test_labels=test_data[copycat_column_names[colname]]\n",
    "        dis_ans=[]\n",
    "        K=5\n",
    "        for j in range(test_features.values.shape[0]):\n",
    "            #print((test_features.values)[j])\n",
    "            dis_lis=0\n",
    "            dis_sum = 0\n",
    "            ans=0\n",
    "            maxx_dis,maxx_lb=0,0\n",
    "            distance=0\n",
    "            for i in range(train_features.values.shape[0]):\n",
    "        #print((train_features.values)[i])\n",
    "                distance= chisquare(test_features.values[j],train_features.values[i])\n",
    "            \n",
    "        #dis_lis_lab.append(distance)\n",
    "                dis_lis = distance*train_labels.values[i]\n",
    "                if maxx_dis < distance:\n",
    "                    maxx_dis = distance\n",
    "                    maxx_lb = train_labels.values[i]\n",
    "        \n",
    "#         {distance:train_labels.values[i]}\n",
    "#         print(dis_lis_lab)\n",
    "                dis_sum+= distance\n",
    "    #if cat retrun max_lb\n",
    "    \n",
    "        \n",
    "            ans=maxx_lb   \n",
    "    \n",
    "    \n",
    "            dis_ans.append(ans)  #print(dis_ans)\n",
    "    \n",
    "        print(cat_names[colname],\":\",np.sqrt(np.sum((test_labels.values - np.array(dis_ans))**2)),\"after sampling\",fr,\"% of data\",)#finding accuracy by taking out root mean square value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
